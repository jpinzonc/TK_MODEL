{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TO CLASSIFY _PRODUCTS_ \n",
    "Use for training data from Indianapolis stores provided by David. \n",
    "\n",
    "The data includes variables that were used in the calculation of the product score and also other variables (e.g. revenue)\n",
    "\n",
    "The table include these columns:\n",
    "\n",
    "-   No_cust:        Number of customers buying the product\n",
    "-   frequency: Number of times the product was purchased in the period (1 yr)\n",
    "-   No_branches: Number of branches that sold the product\n",
    "-   qty: Total quantity of product sold\n",
    "-   total_rev: Total revenue for the product\n",
    "-   prod_score: score of the product as determined in the Indianapolis exercise. Takes values from 0 to 6. It is used to determine the category. \n",
    "-   Desc: description of the product - Not necesary for the analysis - was included to confirm product identity\n",
    "-   Stockcode : Product stockcode used to link it with the procode - this is repeated a couple of times. (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier # keras wrapper for sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Raw data (used to calculate the product score) __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProCode</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>pro_code</th>\n",
       "      <th>pro_stockcode</th>\n",
       "      <th>pro_supplier</th>\n",
       "      <th>pro_desc</th>\n",
       "      <th>sup_commodity</th>\n",
       "      <th>sup_name</th>\n",
       "      <th>sup_fullname</th>\n",
       "      <th>ana_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>982619</td>\n",
       "      <td>TAYLOR SECURITY &amp; LOCK</td>\n",
       "      <td>0253-3026</td>\n",
       "      <td>982619.0</td>\n",
       "      <td>0253-3026</td>\n",
       "      <td>1003282.0</td>\n",
       "      <td>POST &amp; PACKING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAYLOR SECURITY</td>\n",
       "      <td>]TAYLOR SECURITY &amp; LOCK</td>\n",
       "      <td>EXPENSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1065470</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>0285-6288</td>\n",
       "      <td>1065470.0</td>\n",
       "      <td>0285-6288</td>\n",
       "      <td>1005292.0</td>\n",
       "      <td>LED DRIVER</td>\n",
       "      <td>N</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>LAMPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047093</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>0278-6463</td>\n",
       "      <td>1047093.0</td>\n",
       "      <td>0278-6463</td>\n",
       "      <td>1005292.0</td>\n",
       "      <td>Post &amp; Packing</td>\n",
       "      <td>N</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>LAMPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157807</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>0312-5187</td>\n",
       "      <td>1157807.0</td>\n",
       "      <td>0312-5187</td>\n",
       "      <td>1005292.0</td>\n",
       "      <td>TEST WEB</td>\n",
       "      <td>N</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>1 SOURCE LED</td>\n",
       "      <td>LAMPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914951</td>\n",
       "      <td>100 WATT NETWORK</td>\n",
       "      <td>0238-4598</td>\n",
       "      <td>914951.0</td>\n",
       "      <td>0238-4598</td>\n",
       "      <td>1001482.0</td>\n",
       "      <td>POST &amp; PACKING</td>\n",
       "      <td>N</td>\n",
       "      <td>100 WATT NET</td>\n",
       "      <td>100 WATT NETWORK</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProCode                Supplier  Stockcode   pro_code pro_stockcode  \\\n",
       "0   982619  TAYLOR SECURITY & LOCK  0253-3026   982619.0     0253-3026   \n",
       "1  1065470            1 SOURCE LED  0285-6288  1065470.0     0285-6288   \n",
       "2  1047093            1 SOURCE LED  0278-6463  1047093.0     0278-6463   \n",
       "3  1157807            1 SOURCE LED  0312-5187  1157807.0     0312-5187   \n",
       "4   914951        100 WATT NETWORK  0238-4598   914951.0     0238-4598   \n",
       "\n",
       "   pro_supplier        pro_desc sup_commodity         sup_name  \\\n",
       "0     1003282.0  POST & PACKING           NaN  TAYLOR SECURITY   \n",
       "1     1005292.0      LED DRIVER             N     1 SOURCE LED   \n",
       "2     1005292.0  Post & Packing             N     1 SOURCE LED   \n",
       "3     1005292.0        TEST WEB             N     1 SOURCE LED   \n",
       "4     1001482.0  POST & PACKING             N     100 WATT NET   \n",
       "\n",
       "              sup_fullname       ana_desc  \n",
       "0  ]TAYLOR SECURITY & LOCK       EXPENSES  \n",
       "1             1 SOURCE LED          LAMPS  \n",
       "2             1 SOURCE LED          LAMPS  \n",
       "3             1 SOURCE LED          LAMPS  \n",
       "4         100 WATT NETWORK  MISCELLANEOUS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prods_desc = pd.read_excel('..\\\\00_Local_db\\\\FILES\\\\Pro-Code-Listing_JP.xlsx')\n",
    "prods_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17359, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('01_raw_data\\\\prod_cat.csv', encoding = 'latin1', low_memory=False, dtype= {'cus_code':str})\n",
    "data = data.dropna(axis = 0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18348, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.merge(prods_desc[['Stockcode', 'ProCode']], how='left', on='Stockcode').drop(['Desc'], axis = 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_cust</th>\n",
       "      <th>frequecy</th>\n",
       "      <th>No_braches</th>\n",
       "      <th>qty</th>\n",
       "      <th>total_rev</th>\n",
       "      <th>prod_score</th>\n",
       "      <th>Stockcode</th>\n",
       "      <th>ProCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>387.45</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0014-5854</td>\n",
       "      <td>48617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>387.45</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0014-5854</td>\n",
       "      <td>1311827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>387.45</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0014-5854</td>\n",
       "      <td>48617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>387.45</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0014-5854</td>\n",
       "      <td>1311827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-5884</td>\n",
       "      <td>1311721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-5884</td>\n",
       "      <td>1311721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-5884</td>\n",
       "      <td>48627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-5884</td>\n",
       "      <td>48627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-6022</td>\n",
       "      <td>1312665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-6022</td>\n",
       "      <td>48673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-6022</td>\n",
       "      <td>48673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0014-6022</td>\n",
       "      <td>1312665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0186-5580</td>\n",
       "      <td>1312428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0186-5580</td>\n",
       "      <td>621858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0186-5580</td>\n",
       "      <td>621858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0186-5580</td>\n",
       "      <td>1312428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0237-2061</td>\n",
       "      <td>1312541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0237-2061</td>\n",
       "      <td>1312541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0237-2061</td>\n",
       "      <td>896173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0237-2061</td>\n",
       "      <td>896173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>53.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0258-4095</td>\n",
       "      <td>1313017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>53.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0258-4095</td>\n",
       "      <td>968586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>53.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0258-4095</td>\n",
       "      <td>1313017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>53.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0258-4095</td>\n",
       "      <td>968586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12261</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42.12</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0302-1660</td>\n",
       "      <td>1122325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42.12</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0302-1660</td>\n",
       "      <td>1122325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12260</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42.12</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0302-1660</td>\n",
       "      <td>1145755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12258</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>42.12</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0302-1660</td>\n",
       "      <td>1145755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3120.00</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0316-5132</td>\n",
       "      <td>1171345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3120.00</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0316-5132</td>\n",
       "      <td>1312167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3120.00</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0316-5132</td>\n",
       "      <td>1312167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3120.00</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0316-5132</td>\n",
       "      <td>1171345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1320.00</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0317-9715</td>\n",
       "      <td>1312166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1320.00</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0317-9715</td>\n",
       "      <td>1312166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1320.00</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0317-9715</td>\n",
       "      <td>1176220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1320.00</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0317-9715</td>\n",
       "      <td>1176220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>79.48</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0330-0240</td>\n",
       "      <td>1223563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>79.48</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0330-0240</td>\n",
       "      <td>1221185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>79.48</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0330-0240</td>\n",
       "      <td>1221185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>79.48</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0330-0240</td>\n",
       "      <td>1223563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       No_cust  \\tfrequecy  \\tNo_braches  qty  total_rev  prod_score  \\\n",
       "6441         2           6             2   27     387.45       0.044   \n",
       "247          2           6             2   27     387.45       0.044   \n",
       "248          2           6             2   27     387.45       0.044   \n",
       "6440         2           6             2   27     387.45       0.044   \n",
       "245          0           0             2    1      11.55       0.000   \n",
       "6438         0           0             2    1      11.55       0.000   \n",
       "6439         0           0             2    1      11.55       0.000   \n",
       "246          0           0             2    1      11.55       0.000   \n",
       "6450         0           0             2    1      26.88       0.000   \n",
       "6451         0           0             2    1      26.88       0.000   \n",
       "258          0           0             2    1      26.88       0.000   \n",
       "257          0           0             2    1      26.88       0.000   \n",
       "6446         0           0             2    2      58.80       0.050   \n",
       "6447         0           0             2    2      58.80       0.050   \n",
       "254          0           0             2    2      58.80       0.050   \n",
       "253          0           0             2    2      58.80       0.050   \n",
       "255          1           1             2    3     121.50       0.200   \n",
       "6448         1           1             2    3     121.50       0.200   \n",
       "6449         1           1             2    3     121.50       0.200   \n",
       "256          1           1             2    3     121.50       0.200   \n",
       "259          0           0             2    9      53.55       0.000   \n",
       "6453         0           0             2    9      53.55       0.000   \n",
       "6452         0           0             2    9      53.55       0.000   \n",
       "260          0           0             2    9      53.55       0.000   \n",
       "12261        4           4             4    4      42.12       1.250   \n",
       "12259        4           4             4    4      42.12       1.250   \n",
       "12260        4           4             4    4      42.12       1.250   \n",
       "12258        4           4             4    4      42.12       1.250   \n",
       "252          2           6             2   26    3120.00       0.050   \n",
       "6444         2           6             2   26    3120.00       0.050   \n",
       "251          2           6             2   26    3120.00       0.050   \n",
       "6445         2           6             2   26    3120.00       0.050   \n",
       "6442         1           1             2   11    1320.00       0.200   \n",
       "249          1           1             2   11    1320.00       0.200   \n",
       "250          1           1             2   11    1320.00       0.200   \n",
       "6443         1           1             2   11    1320.00       0.200   \n",
       "10968        0           0             2   10      79.48       0.050   \n",
       "10969        0           0             2   10      79.48       0.050   \n",
       "2324         0           0             2   10      79.48       0.050   \n",
       "2323         0           0             2   10      79.48       0.050   \n",
       "\n",
       "       Stockcode  ProCode  \n",
       "6441   0014-5854    48617  \n",
       "247    0014-5854  1311827  \n",
       "248    0014-5854    48617  \n",
       "6440   0014-5854  1311827  \n",
       "245    0014-5884  1311721  \n",
       "6438   0014-5884  1311721  \n",
       "6439   0014-5884    48627  \n",
       "246    0014-5884    48627  \n",
       "6450   0014-6022  1312665  \n",
       "6451   0014-6022    48673  \n",
       "258    0014-6022    48673  \n",
       "257    0014-6022  1312665  \n",
       "6446   0186-5580  1312428  \n",
       "6447   0186-5580   621858  \n",
       "254    0186-5580   621858  \n",
       "253    0186-5580  1312428  \n",
       "255    0237-2061  1312541  \n",
       "6448   0237-2061  1312541  \n",
       "6449   0237-2061   896173  \n",
       "256    0237-2061   896173  \n",
       "259    0258-4095  1313017  \n",
       "6453   0258-4095   968586  \n",
       "6452   0258-4095  1313017  \n",
       "260    0258-4095   968586  \n",
       "12261  0302-1660  1122325  \n",
       "12259  0302-1660  1122325  \n",
       "12260  0302-1660  1145755  \n",
       "12258  0302-1660  1145755  \n",
       "252    0316-5132  1171345  \n",
       "6444   0316-5132  1312167  \n",
       "251    0316-5132  1312167  \n",
       "6445   0316-5132  1171345  \n",
       "6442   0317-9715  1312166  \n",
       "249    0317-9715  1312166  \n",
       "250    0317-9715  1176220  \n",
       "6443   0317-9715  1176220  \n",
       "10968  0330-0240  1223563  \n",
       "10969  0330-0240  1221185  \n",
       "2324   0330-0240  1221185  \n",
       "2323   0330-0240  1223563  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(keep = False)].sort_values(by='Stockcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17349, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset = 'Stockcode') # There were duplicated rows = same stockcode, these come from different manufacturers \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 'optimization' See the excel summary for data on this.  \n",
    "data['prod_cat'] = np.where((data.prod_score <= 1),0,\n",
    "                            np.where((data.prod_score <=1.5),1,\n",
    "                            np.where((data.prod_score <=2),2,\n",
    "                            np.where((data.prod_score <=2.5),3,\n",
    "                            np.where((data.prod_score <=3),4,\n",
    "                            np.where((data.prod_score <=4),5,\n",
    "                            np.where((data.prod_score<=5),6,7)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13273\n",
       "1      481\n",
       "2      920\n",
       "3      716\n",
       "4      439\n",
       "5      669\n",
       "6      572\n",
       "7      279\n",
       "Name: prod_cat, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.prod_cat.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17349"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.ProCode.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITITAL ANN model\n",
    "\n",
    "### Split data into features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17349, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['prod_score', 'Stockcode'], axis = 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_cust</th>\n",
       "      <th>frequecy</th>\n",
       "      <th>No_braches</th>\n",
       "      <th>qty</th>\n",
       "      <th>total_rev</th>\n",
       "      <th>ProCode</th>\n",
       "      <th>prod_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>51.03</td>\n",
       "      <td>634020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>66.41</td>\n",
       "      <td>850648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>62.61</td>\n",
       "      <td>850649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41.75</td>\n",
       "      <td>1040875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>291.58</td>\n",
       "      <td>1036765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_cust  \\tfrequecy  \\tNo_braches  qty  total_rev  ProCode  prod_cat\n",
       "0        5           5             2    5      51.03   634020         0\n",
       "1        2           2             1    6      66.41   850648         0\n",
       "2        9          12             3   14      62.61   850649         0\n",
       "3        0           0             1    4      41.75  1040875         0\n",
       "4        2           2             2    9     291.58  1036765         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data original 17349, target: 17349, features: 17349\n"
     ]
    }
   ],
   "source": [
    "target = data.prod_cat.values\n",
    "features = data.drop(['prod_cat'], axis=1).values\n",
    "print ('Data original %d, target: %d, features: %d' % (data.shape[0], target.shape[0], features.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(features, target, test_size= 0.25, random_state=1)\n",
    "# unmask for validation purposes\n",
    "X_train, X_val, y_train, y_val    = train_test_split(X_train, y_train, test_size= 0.20, random_state=1)\n",
    "\n",
    "X_train_names = X_train[:,5]\n",
    "X_train = X_train[:,0:5]\n",
    "\n",
    "X_test_names = X_test[:,5]\n",
    "X_test = X_test[:,0:5]\n",
    "                  \n",
    "X_val_names = X_val[:,5]\n",
    "X_val = X_val[:,0:5]\n",
    "\n",
    "# Standarizing the variables \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val   = sc.transform(X_val)\n",
    "X_test  = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing the target variable as it has multiple labels (categories = 9)\n",
    "categorical_labels       = to_categorical(y_train, num_classes = None)\n",
    "categorical_labels_y_tes = to_categorical(y_test, num_classes = None)\n",
    "categorical_labels_y_val = to_categorical(y_val, num_classes = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the initial model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = 8 # Used during the category optimization \n",
    "def classifier_model(activator,optimizer, initializer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 10, kernel_initializer = initializer, activation = activator, input_dim = 5))\n",
    "    classifier.add(Dense(units = 10, kernel_initializer = initializer, activation = activator))\n",
    "    classifier.add(Dense(units = categories,  kernel_initializer = initializer, activation = 'softmax'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUMP TO OPTIMIZED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model with the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10408/10408 [==============================] - 1s 125us/step - loss: 0.7234 - acc: 0.7903\n",
      "Epoch 2/10\n",
      "10408/10408 [==============================] - 1s 96us/step - loss: 0.3782 - acc: 0.8483\n",
      "Epoch 3/10\n",
      "10408/10408 [==============================] - 1s 93us/step - loss: 0.2668 - acc: 0.9002\n",
      "Epoch 4/10\n",
      "10408/10408 [==============================] - 1s 96us/step - loss: 0.2060 - acc: 0.9307\n",
      "Epoch 5/10\n",
      "10408/10408 [==============================] - 1s 96us/step - loss: 0.1678 - acc: 0.9487\n",
      "Epoch 6/10\n",
      "10408/10408 [==============================] - 1s 97us/step - loss: 0.1438 - acc: 0.9555\n",
      "Epoch 7/10\n",
      "10408/10408 [==============================] - 1s 96us/step - loss: 0.1261 - acc: 0.9602\n",
      "Epoch 8/10\n",
      "10408/10408 [==============================] - 1s 95us/step - loss: 0.1140 - acc: 0.9628\n",
      "Epoch 9/10\n",
      "10408/10408 [==============================] - 1s 94us/step - loss: 0.1066 - acc: 0.9637\n",
      "Epoch 10/10\n",
      "10408/10408 [==============================] - 1s 88us/step - loss: 0.0993 - acc: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a7062e2e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activator   = 'relu'\n",
    "optimizer   = 'adam'\n",
    "initializer = 'uniform'\n",
    "classifier = classifier_model(activator, optimizer, initializer)\n",
    "classifier.fit(X_train, categorical_labels, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using relu - as raw model above - as activator\n",
    "activator   = 'relu'\n",
    "optimizer   = 'adam'\n",
    "initializer = 'uniform'\n",
    "cv = 10 \n",
    "classifier_cv = KerasClassifier(build_fn = classifier_model, \n",
    "                                activator = activator, \n",
    "                                optimizer = optimizer,\n",
    "                                initializer = initializer,\n",
    "                                batch_size = 10, \n",
    "                                epochs = 10, \n",
    "                                verbose = 0)\n",
    "accuracies = cross_val_score(estimator = classifier_cv, X = X_train, y = categorical_labels, cv = cv)\n",
    "\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv accuracy (relu) = 96.9351% +/- 0.9028\n"
     ]
    }
   ],
   "source": [
    "# Mean cv accuracy \n",
    "print('Mean cv accuracy (relu) = {:.4f}% +/- {:.4f}'.format(mean *100, variance *100) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Retrain if necesary \n",
    "activator = 'relu'\n",
    "classifier = classifier_model(activator)\n",
    "classifier.fit(X_train, categorical_labels, batch_size = 10, epochs = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy = 96.8498%, Loss = 0.0955\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier.evaluate(X_val, categorical_labels_y_val, batch_size = 10, verbose = 0)\n",
    "print(\"Validation set accuracy = {:.4f}%, Loss = {:.4f}\".format(accuracy* 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.51\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier.evaluate(X_train,categorical_labels , batch_size = 128, verbose = 0)\n",
    "print(round(accuracy*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "- did it 'manually' as GridSearch does not handle multilabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform 98.17 98.46\n",
      "he_normal 96.64 96.81\n",
      "he_uniform 96.89 97.27\n",
      "Orthogonal 98.01 98.27\n",
      "VarianceScaling 97.74 97.81\n",
      "TruncatedNormal 97.98 98.35\n",
      "Constant 76.48 76.87\n",
      "Ones 85.34 86.09\n",
      "Zeros 76.48 76.87\n",
      "lecun_normal 96.72 96.7\n",
      "lecun_uniform 96.92 97.04\n",
      "RandomNormal 98.0 98.35\n",
      "RandomUniform 96.47 96.66\n",
      "glorot_normal 97.85 97.77\n",
      "glorot_uniform 97.39 97.58\n"
     ]
    }
   ],
   "source": [
    "# Added this one as early in the analysis the initializer appeared important in the model. \n",
    "# After optimizing the categories, it seems that for this particular case it may not be important. \n",
    "activator    = 'relu'\n",
    "optimizer    = 'adam'\n",
    "initializers =  ['uniform'  , 'he_normal'   , 'he_uniform'   , 'Orthogonal'  , 'VarianceScaling', 'TruncatedNormal', 'Constant'     , 'Ones',\n",
    "                 'Zeros'    , 'lecun_normal', 'lecun_uniform', 'RandomNormal', 'RandomUniform'  ,  'glorot_normal', 'glorot_uniform'] #'Identity'       ,\n",
    "for initializer in initializers:\n",
    "    # Retrain if necesary \n",
    "    classifier_op = classifier_model(activator, optimizer, initializer)\n",
    "    classifier_op.fit(X_train, categorical_labels, batch_size = 10, epochs = 10, verbose = 0)\n",
    "    loss, accuracy       = classifier_op.evaluate(X_train,categorical_labels , batch_size = 10, verbose = 0)\n",
    "    loss_ev, accuracy_ev = classifier_op.evaluate(X_val, categorical_labels_y_val, batch_size = 10, verbose = 0)\n",
    "\n",
    "    print(initializer, round(accuracy*100,2), round(accuracy_ev*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear 92.22 92.89\n",
      "relu 97.29 97.62\n",
      "sigmoid 87.23 87.94\n",
      "softplus 93.97 94.54\n",
      "softsign 94.72 95.35\n",
      "softmax 86.12 86.17\n",
      "tanh 95.82 96.47\n"
     ]
    }
   ],
   "source": [
    "activators  = ['linear', 'relu', 'sigmoid', 'softplus', 'softsign', 'softmax', 'tanh']\n",
    "optimizer   = 'adam'\n",
    "initializer = 'uniform'\n",
    "for activator in activators:\n",
    "    # Retrain if necesary \n",
    "    classifier_op = classifier_model(activator, optimizer, initializer)\n",
    "    classifier_op.fit(X_train, categorical_labels, batch_size = 10, epochs = 10, verbose = 0)\n",
    "    loss, accuracy       = classifier_op.evaluate(X_train,categorical_labels , batch_size = 10, verbose = 0)\n",
    "    loss_ev, accuracy_ev = classifier_op.evaluate(X_val, categorical_labels_y_val, batch_size = 10, verbose = 0)\n",
    "\n",
    "    print(activator, round(accuracy*100,2), round(accuracy_ev*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adadelta 94.93 95.04\n",
      "Adagrad 90.31 90.93\n",
      "adam 97.46 98.23\n",
      "Adamax 96.71 97.31\n",
      "Nadam 97.47 97.93\n",
      "sgd 85.09 85.75\n",
      "RMSprop 97.03 97.31\n"
     ]
    }
   ],
   "source": [
    "activator   = 'relu'\n",
    "optimizers  = ['Adadelta', 'Adagrad', 'adam', 'Adamax', 'Nadam', 'sgd', 'RMSprop']\n",
    "initializer = 'uniform'\n",
    "for optimizer in optimizers:\n",
    "    classifier_op = classifier_model(activator, optimizer, initializer)\n",
    "    classifier_op.fit(X_train, categorical_labels, batch_size = 10, epochs = 10, verbose = 0)\n",
    "    loss, accuracy       = classifier_op.evaluate(X_train,categorical_labels , batch_size = 10, verbose = 0)\n",
    "    loss_ev, accuracy_ev = classifier_op.evaluate(X_val, categorical_labels_y_val, batch_size = 10, verbose = 0)\n",
    "\n",
    "    print(optimizer, round(accuracy*100,2), round(accuracy_ev*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 96.92 97.12\n",
      "20 98.16 98.23\n",
      "50 98.23 98.46\n",
      "100 98.34 98.5\n",
      "200 98.2 98.27\n"
     ]
    }
   ],
   "source": [
    "activator   = 'relu'\n",
    "optimizer   = 'adam'\n",
    "initializer = 'uniform'\n",
    "epochs = [10, 20, 50, 100, 200]\n",
    "for epoch in epochs:\n",
    "    classifier_op = classifier_model(activator, optimizer, initializer)\n",
    "    classifier_op.fit(X_train, categorical_labels, batch_size = 10, epochs = epoch, verbose = 0)\n",
    "    loss, accuracy       = classifier_op.evaluate(X_train,categorical_labels , batch_size = 10, verbose = 0)\n",
    "    loss_ev, accuracy_ev = classifier_op.evaluate(X_val, categorical_labels_y_val, batch_size = 10, verbose = 0)\n",
    "\n",
    "    print(epoch, round(accuracy*100,2), round(accuracy_ev*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZED MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a21d39588>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activator   = 'relu'\n",
    "optimizer   = 'adam'\n",
    "initializer = 'uniform'\n",
    "epoch = 50 \n",
    "classifier_opt = classifier_model(activator, optimizer, initializer)\n",
    "classifier_opt.fit(X_train, categorical_labels, batch_size = 10, epochs = epoch, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.06931806e-08,   4.95392472e-01,   5.04607558e-01],\n",
       "       [  1.00000000e+00,   9.76902828e-22,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  9.99999881e-01,   9.84939774e-08,   2.59020918e-18, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  9.09953557e-10,   9.99492168e-01,   5.07817778e-04, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   5.69479016e-22,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  8.70742855e-17,   1.95035283e-02,   9.80471790e-01, ...,\n",
       "          2.74200015e-28,   2.22433697e-36,   0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting on the test set \n",
    "y_pred = classifier_opt.predict(X_test)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97657102987506517"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(categorical_labels_y_tes, y_pred.round(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "      <th>procode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>138054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1072505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>951332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535875.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual    procode\n",
       "0        7.0     6.0   138054.0\n",
       "1        0.0     0.0  1072505.0\n",
       "2        0.0     0.0   426488.0\n",
       "3        0.0     0.0   951332.0\n",
       "4        0.0     0.0   535875.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = y_pred.argmax(axis=-1)\n",
    "y_a = pd.DataFrame([y_classes])\n",
    "y_b = pd.DataFrame([y_test])\n",
    "y_c = pd.DataFrame([X_test_names])\n",
    "y_a = pd.concat((y_a,y_b, y_c)).T\n",
    "y_a.columns = ['predicted', 'actual','procode']\n",
    "y_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.6717%, Loss = 0.0669\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on the test set\n",
    "loss, accuracy = classifier_opt.evaluate(X_test, categorical_labels_y_tes, batch_size=10, verbose=0)\n",
    "print(\"Accuracy = {:.4f}%, Loss = {:.4f}\".format(accuracy* 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    28\n",
       "2.0    21\n",
       "3.0     9\n",
       "4.0    14\n",
       "5.0     9\n",
       "6.0    19\n",
       "7.0     1\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of mismatches within the test set\n",
    "y_a['dif'] = np.where(y_a.predicted == y_a.actual, 0, 1)\n",
    "y_a[y_a['dif'] == 1].actual.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS BY DISTRICT MANAGER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__John Lewis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17851, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_jl_ = pd.read_csv('01_raw_data\\\\John_Lewis_p.csv',encoding = 'latin1')\n",
    "data_jl_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_cust</th>\n",
       "      <th>frequency</th>\n",
       "      <th>No_branches</th>\n",
       "      <th>qty</th>\n",
       "      <th>total_rev</th>\n",
       "      <th>procode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>755.08</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>936.19</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>575.60</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>585.53</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_cust  frequency  No_branches   qty  total_rev  procode\n",
       "0       22         30            5  45.0     755.08      203\n",
       "1       16         18            3  27.0     936.19      204\n",
       "2        5          5            3   7.0     575.60      206\n",
       "3        1          1            1   1.0      49.00      210\n",
       "4        8          8            4   9.0     585.53      243"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_jl_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data original 17851,  features: 17851\n"
     ]
    }
   ],
   "source": [
    "features_jl = data_jl_.values\n",
    "print ('Data original %d,  features: %d' % (data_jl_.shape[0], features_jl.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "jl_cust_name = features_jl[:,5]\n",
    "jl_val  = features_jl[:,0:5]\n",
    "jl_val   = sc.transform(jl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.44716123e-23,   1.94457668e-16,   3.22712027e-03, ...,\n",
       "          7.67604242e-13,   2.05154444e-20,   0.00000000e+00],\n",
       "       [  9.99999285e-01,   7.00697171e-07,   5.09464693e-11, ...,\n",
       "          2.32954323e-37,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   9.73993330e-10,   8.66982889e-19, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   8.63422497e-20, ...,\n",
       "          6.28006577e-01,   1.04592857e-06,   6.89904477e-22],\n",
       "       [  1.00000000e+00,   1.63945844e-22,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   3.24483829e-10,   6.68755259e-18, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting on the test set \n",
    "jl_pred = classifier_opt.predict(jl_val)\n",
    "jl_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    13698\n",
       "1.0      256\n",
       "2.0      993\n",
       "3.0      750\n",
       "4.0      504\n",
       "5.0      723\n",
       "6.0      489\n",
       "7.0      438\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "17851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>procode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1007423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1068796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1068864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1068869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1068878.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction    procode\n",
       "8925          0.0  1007423.0\n",
       "11559         0.0  1068796.0\n",
       "11560         0.0  1068864.0\n",
       "11561         0.0  1068869.0\n",
       "11562         0.0  1068878.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jl_classes = jl_pred.argmax(axis=-1)\n",
    "a_jl = pd.DataFrame([jl_classes])\n",
    "b_jl = pd.DataFrame([jl_cust_name])\n",
    "a_jl = pd.concat((a_jl,b_jl)).T\n",
    "a_jl.columns = ['prediction', 'procode']\n",
    "a_jl = a_jl.sort_values(by='prediction')\n",
    "display(a_jl.prediction.value_counts().sort_index())\n",
    "display(len(a_jl))\n",
    "a_jl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_jl2 = a_jl.merge(y_a[['procode', 'predicted']], how = 'left', on = 'procode')\n",
    "a_jl2 = a_jl2.merge(data[['ProCode', 'prod_cat']], how = 'left', right_on='ProCode', left_on = 'procode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge.Pinzon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py:179: UserWarning: 'colors' is being deprecated. Please use 'color'instead of 'colors'\n",
      "  warnings.warn((\"'colors' is being deprecated. Please use 'color'\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKIAAAEyCAYAAADJOnhuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a310eb320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_jl2['dif'] = a_jl2.prod_cat.sub(a_jl2.prediction)\n",
    "a_jl2[[ 'prod_cat', 'prediction']].plot.hist(figsize = (20,5), bins = 9,  colors = ['r', 'b'], alpha = 0.5)\n",
    "plt.xticks(color = 'gray')\n",
    "plt.yticks(color = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING THE MODEL AND THE SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02_data/product_scaler_3_15_19_p.pkl']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "classifier_opt.save('02_data/product_classifier_opt_3_15_19_p.hdf5')\n",
    "joblib.dump(sc, '02_data/product_scaler_3_15_19_p.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
